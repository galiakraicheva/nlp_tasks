{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7384c1e-acce-480a-9c86-76a0029f689c",
   "metadata": {},
   "source": [
    "# LangChain Library\n",
    "\n",
    "Since the task mentions LangChain, I will do the taks with LangChain too. Again, first, I try with 1024 tokens and a short summary to see how it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61d9d633-ac79-42fa-a233-60c4ee9ef766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Artificial intelligence is a branch of computer science that develops machine systems capable of demonstrating behaviors linked to human intelligence. AI programs use data collected from different interactions to improve the way they mimic humans in order to perform tasks such as learning, planning, knowledge representation, perception and problem-solving.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from transformers import pipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "# Step 1: Scrape Text from a Website\n",
    "def scrape_website(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    paragraphs = [p.get_text(strip=True) for p in soup.find_all('p')]\n",
    "    text = ' '.join(paragraphs)  # Extract only paragraph text\n",
    "    return text\n",
    "\n",
    "# Step 2: Setup Summarization Model\n",
    "def get_summarization_chain():\n",
    "    # Load the summarization pipeline from Hugging Face\n",
    "    summarization_pipeline = pipeline(\n",
    "        \"summarization\",\n",
    "        model=\"facebook/bart-large-cnn\",\n",
    "        framework=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Wrap the Hugging Face model inside a LangChain-compatible pipeline\n",
    "    summarization_llm = HuggingFacePipeline(pipeline=summarization_pipeline)\n",
    "\n",
    "    # Define the prompt template\n",
    "    summarization_prompt = PromptTemplate.from_template(\n",
    "        \"Summarize the following text in a clear and concise way:\\n\\n{text}\\n\\nSummary:\"\n",
    "    )\n",
    "\n",
    "    # Use RunnableLambda to make the pipeline compatible\n",
    "    return RunnableLambda(lambda inputs: summarization_llm.invoke(inputs[\"text\"]))\n",
    "\n",
    "# Step 3: Generate Summary\n",
    "def summarize_website(url):\n",
    "    text = scrape_website(url)\n",
    "\n",
    "    # Truncate the text if it's too long\n",
    "    max_input_length = 1024\n",
    "    text = text[:max_input_length]\n",
    "\n",
    "    # Get the summarization chain\n",
    "    summarization_chain = get_summarization_chain()\n",
    "\n",
    "    # Generate the summary using invoke()\n",
    "    summary = summarization_chain.invoke({\"text\": text})\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://www.wix.com/encyclopedia/definition/artificial-intelligence\"\n",
    "    summary = summarize_website(url)\n",
    "    print(f\"Summary:\\n{summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8252c228-50c6-453c-84ca-f490a581299f",
   "metadata": {},
   "source": [
    "The summary is not great but the model is doing good so I add the title, chunck the text and make the summary longer. \n",
    "\n",
    "### Revised model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81eee841-b975-4f37-bfe8-b64bb7d6061c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Your max_length is set to 142, but your input_length is only 88. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=44)\n",
      "Your max_length is set to 142, but your input_length is only 96. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n",
      "Your max_length is set to 142, but your input_length is only 108. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n",
      "Your max_length is set to 142, but your input_length is only 99. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=49)\n",
      "Your max_length is set to 142, but your input_length is only 108. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n",
      "Your max_length is set to 142, but your input_length is only 105. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=52)\n",
      "Your max_length is set to 142, but your input_length is only 104. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=52)\n",
      "Your max_length is set to 142, but your input_length is only 110. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=55)\n",
      "Your max_length is set to 142, but your input_length is only 5. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=2)\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Artificial intelligence: a new way to improve our systems\n",
      "Summary: Artificial intelligence is a branch of computer science that develops machine systems capable of demonstrating behaviors linked to human intelligence. The purpose of AI is to improve the systems we already use by automating tasks to make them more efficient. Technology is used for a wide range of applications, including inweb development, chatbots for customer service, product recommendations based on userâ€™s habits, speech recognition.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import textwrap\n",
    "from transformers import pipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "# Step 1: Scrape Text from a Website\n",
    "def scrape_website(url, max_chars=4000):\n",
    "    \"\"\"Extracts paragraph text from a webpage and truncates it to a reasonable length.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch webpage. Status code: {response.status_code}\")\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    paragraphs = [p.get_text(strip=True) for p in soup.find_all('p')]\n",
    "    text = ' '.join(paragraphs)\n",
    "    return text[:max_chars] if len(text) > max_chars else text\n",
    "\n",
    "# Step 2: Chunking for Large Texts\n",
    "def chunk_text(text, max_tokens=500):\n",
    "    \"\"\"Splits long text into smaller chunks to fit model constraints.\"\"\"\n",
    "    return textwrap.wrap(text, width=max_tokens)\n",
    "\n",
    "# Step 3: Setup LangChain Summarization Model\n",
    "def get_summarization_chain():\n",
    "    \"\"\"Loads the summarization pipeline wrapped inside LangChain.\"\"\"\n",
    "    summarization_pipeline = pipeline(\n",
    "        \"summarization\",\n",
    "        model=\"facebook/bart-large-cnn\",\n",
    "        framework=\"pt\"\n",
    "    )\n",
    "    summarization_llm = HuggingFacePipeline(pipeline=summarization_pipeline)\n",
    "    return RunnableLambda(lambda inputs: summarization_llm.invoke(inputs[\"text\"]))\n",
    "\n",
    "# Step 4: Setup LangChain Title Generation Model (Fixing Issue)\n",
    "def get_title_chain():\n",
    "    \"\"\"Loads the title generator pipeline wrapped inside LangChain.\"\"\"\n",
    "    title_pipeline = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=\"google/flan-t5-base\",\n",
    "        framework=\"pt\"\n",
    "    )\n",
    "    title_llm = HuggingFacePipeline(pipeline=title_pipeline)\n",
    "\n",
    "    return RunnableLambda(lambda inputs: title_llm.invoke(inputs[\"text\"]))\n",
    "\n",
    "# Step 5: Generate Summary with LangChain\n",
    "def summarize_large_text(text):\n",
    "    \"\"\"Summarizes long text in chunks and then summarizes the combined result.\"\"\"\n",
    "    summarization_chain = get_summarization_chain()\n",
    "    chunks = chunk_text(text)\n",
    "    \n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        summary = summarization_chain.invoke({\"text\": chunk}).strip()\n",
    "        summaries.append(summary)\n",
    "\n",
    "    # If there are multiple summaries, summarize them again\n",
    "    if len(summaries) > 1:\n",
    "        combined_text = \" \".join(summaries)\n",
    "        final_summary = summarization_chain.invoke({\"text\": combined_text}).strip()\n",
    "    else:\n",
    "        final_summary = summaries[0]\n",
    "\n",
    "    return final_summary\n",
    "\n",
    "# Step 6: Generate Title with Fixes\n",
    "def generate_title(summary):\n",
    "    \"\"\"Creates a short, engaging title using LangChain with better formatting.\"\"\"\n",
    "    title_chain = get_title_chain()\n",
    "\n",
    "    # Enforce a shorter title by limiting length & making the instruction explicit\n",
    "    title_prompt = f\"Generate a **short, engaging, and clear title** for the following summary:\\n{summary}\\n\\nTitle:\"\n",
    "    raw_title = title_chain.invoke({\"text\": title_prompt}).strip()\n",
    "\n",
    "    # Clean the title by extracting only the first generated line\n",
    "    clean_title = raw_title.split(\"\\n\")[0]  # Take the first line only\n",
    "\n",
    "    # Further clean long titles (ensuring a concise length)\n",
    "    words = clean_title.split()\n",
    "    if len(words) > 10:  # Limit to 10 words max\n",
    "        clean_title = \" \".join(words[:10])\n",
    "\n",
    "    return clean_title.capitalize()\n",
    "\n",
    "# Step 7: Main Function\n",
    "def summarize_and_title(url):\n",
    "    \"\"\"Extracts text from a URL, summarizes it using LangChain, and generates a title.\"\"\"\n",
    "    try:\n",
    "        text = scrape_website(url)\n",
    "        summary = summarize_large_text(text)\n",
    "        title = generate_title(summary)\n",
    "\n",
    "        return title, summary\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\", \"\"\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://www.wix.com/encyclopedia/definition/artificial-intelligence\"\n",
    "    title, summary = summarize_and_title(url)\n",
    "    print(f\"Title: {title}\\nSummary: {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fbdc20-12dd-465b-b00b-8f24be7d60f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
