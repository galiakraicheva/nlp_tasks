{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d25f25-ec15-4471-8837-8c1be0597275",
   "metadata": {},
   "source": [
    "# LlaMa summarisation\n",
    "\n",
    "Since the task explicitly mentions LlaMa, here is a solution with Llama. The chosen model is the smallest in the 3.2 group to be able to run on my laptop. \n",
    "\n",
    "#### Without LangChain: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1706668-d3d6-42c6-ac33-1977f76fe5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How to build a chatbot for a website\n",
      "Summary: AI is a branch of computer science that develops machine systems capable of demonstrating behaviors linked to human intelligence. AI programs use data collected from different interactions to improve the way they mimic humans in order to perform tasks such as learning, planning, knowledge representation, perception and problem-solving. Artificial intelligence technology is used for a wide range of applications, including in web development, such as automated chatbots for customer service, product recommendations based on a user’s habits, speech recognition, and even to build a website from scratch.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Scrape Text from a Website\n",
    "def scrape_website(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    paragraphs = [p.get_text(strip=True) for p in soup.find_all('p')]\n",
    "    text = ' '.join(paragraphs)\n",
    "    return text\n",
    "\n",
    "# Step 2: Generate Summary and Title using LLaMA 3.2-1B\n",
    "def summarize_and_title(url):\n",
    "    text = scrape_website(url)\n",
    "\n",
    "    # Truncate and clean input text\n",
    "    max_input_length = 1024  # Adjust for token limit\n",
    "    text = text[:max_input_length]\n",
    "\n",
    "    # Initialize tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
    "    llama_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "    # Generate summary\n",
    "    summary_prompt = (\n",
    "        \"Summarize the following text in clear, concise sentences (max 150 words). Focus on the main points:\\n\\n\"\n",
    "        f\"{text}\\n\\n\"\n",
    "        \"Summary:\"\n",
    "    )\n",
    "    summary_output = llama_pipeline(\n",
    "        summary_prompt,\n",
    "        max_new_tokens=200,\n",
    "        num_return_sequences=1,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    raw_summary = summary_output[0][\"generated_text\"]\n",
    "    summary = raw_summary.split(\"Summary:\")[-1].strip().split(\"\\n\")[0]  # Extract the first line of the summary\n",
    "\n",
    "    # Generate title\n",
    "    title_prompt = (\n",
    "        f\"Write a short, engaging title based on the following summary:\\n\\n\"\n",
    "        f\"{summary}\\n\\n\"\n",
    "        \"Title:\"\n",
    "    )\n",
    "    title_output = llama_pipeline(\n",
    "        title_prompt,\n",
    "        max_new_tokens=20,\n",
    "        num_return_sequences=1,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    raw_title = title_output[0][\"generated_text\"]\n",
    "    title = raw_title.split(\"Title:\")[-1].strip().split(\"\\n\")[0]  # Extract the first line of the title\n",
    "\n",
    "    return summary, title\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://www.wix.com/encyclopedia/definition/artificial-intelligence\"\n",
    "    summary, title = summarize_and_title(url)\n",
    "    print(f\"Title: {title}\\nSummary: {summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c3da47-ac9c-4279-b9d6-c3e610a178da",
   "metadata": {},
   "source": [
    "#### With LangChain: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00513b49-4a7f-4187-8835-ab2edece41a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "/var/folders/s8/8q4nspg501l5dtl_1yw_prmr0000gn/T/ipykernel_53171/1315940413.py:42: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  return LLMChain(llm=summarization_llm, prompt=summarization_prompt)\n",
      "/var/folders/s8/8q4nspg501l5dtl_1yw_prmr0000gn/T/ipykernel_53171/1315940413.py:67: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  summaries = [summarization_chain.run({\"text\": chunk}).strip() for chunk in chunks]\n",
      "Your max_length is set to 142, but your input_length is only 101. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 142, but your input_length is only 109. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=54)\n",
      "Your max_length is set to 142, but your input_length is only 121. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=60)\n",
      "Your max_length is set to 142, but your input_length is only 114. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=57)\n",
      "Your max_length is set to 142, but your input_length is only 121. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=60)\n",
      "Your max_length is set to 142, but your input_length is only 118. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=59)\n",
      "Your max_length is set to 142, but your input_length is only 117. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=58)\n",
      "Your max_length is set to 142, but your input_length is only 123. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n",
      "Your max_length is set to 142, but your input_length is only 18. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=9)\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Ai: a new tool for web development\n",
      "Summary: Artificial intelligence is a branch of computer science that develops machine systems capable of demonstrating behaviors linked to human intelligence. AI technology is used for a wide range of applications, including inweb development. It can be used to create chatbots for customer service, product recommendations based on user’s habits, speech recognition, and even tobuild a website from scratch.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import textwrap\n",
    "from transformers import pipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "# Step 1: Scrape Text from a Website\n",
    "def scrape_website(url, max_chars=4000):\n",
    "    \"\"\"Extracts paragraph text from a webpage and truncates it to a reasonable length.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch webpage. Status code: {response.status_code}\")\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    paragraphs = [p.get_text(strip=True) for p in soup.find_all('p')]\n",
    "    text = ' '.join(paragraphs)\n",
    "    return text[:max_chars] if len(text) > max_chars else text\n",
    "\n",
    "# Step 2: Chunking for Large Texts\n",
    "def chunk_text(text, max_tokens=500):\n",
    "    \"\"\"Splits long text into smaller chunks while maintaining coherence.\"\"\"\n",
    "    return textwrap.wrap(text, width=max_tokens)\n",
    "\n",
    "# Step 3: Setup LangChain Summarization Model\n",
    "def get_summarization_chain():\n",
    "    \"\"\"Creates a LangChain summarization chain using Hugging Face pipeline.\"\"\"\n",
    "    summarization_pipeline = pipeline(\n",
    "        \"summarization\",\n",
    "        model=\"facebook/bart-large-cnn\",\n",
    "        framework=\"pt\"\n",
    "    )\n",
    "    summarization_llm = HuggingFacePipeline(pipeline=summarization_pipeline)\n",
    "\n",
    "    summarization_prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=\"Summarize the following text:\\n\\n{text}\\n\\nSummary:\"\n",
    "    )\n",
    "\n",
    "    return LLMChain(llm=summarization_llm, prompt=summarization_prompt)\n",
    "\n",
    "# Step 4: Setup LangChain Title Generation Model\n",
    "def get_title_chain():\n",
    "    \"\"\"Creates a LangChain title generation chain using Hugging Face pipeline.\"\"\"\n",
    "    title_pipeline = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=\"google/flan-t5-base\",\n",
    "        framework=\"pt\"\n",
    "    )\n",
    "    title_llm = HuggingFacePipeline(pipeline=title_pipeline)\n",
    "\n",
    "    title_prompt = PromptTemplate(\n",
    "        input_variables=[\"summary\"],\n",
    "        template=\"Generate a short, engaging, and clear title for the following summary:\\n\\n{summary}\\n\\nTitle:\"\n",
    "    )\n",
    "\n",
    "    return LLMChain(llm=title_llm, prompt=title_prompt)\n",
    "\n",
    "# Step 5: Generate Summary with LangChain\n",
    "def summarize_large_text(text):\n",
    "    \"\"\"Summarizes long text in chunks and then summarizes the combined result.\"\"\"\n",
    "    summarization_chain = get_summarization_chain()\n",
    "    chunks = chunk_text(text)\n",
    "    \n",
    "    summaries = [summarization_chain.run({\"text\": chunk}).strip() for chunk in chunks]\n",
    "\n",
    "    # If multiple summaries, summarize them again\n",
    "    if len(summaries) > 1:\n",
    "        combined_text = \" \".join(summaries)\n",
    "        final_summary = summarization_chain.run({\"text\": combined_text}).strip()\n",
    "    else:\n",
    "        final_summary = summaries[0]\n",
    "\n",
    "    return final_summary\n",
    "\n",
    "# Step 6: Generate Title\n",
    "def generate_title(summary):\n",
    "    \"\"\"Creates a short, engaging title using LangChain.\"\"\"\n",
    "    title_chain = get_title_chain()\n",
    "    raw_title = title_chain.run({\"summary\": summary}).strip()\n",
    "\n",
    "    # Clean title: limit to 10 words max\n",
    "    words = raw_title.split()\n",
    "    clean_title = \" \".join(words[:10]) if len(words) > 10 else raw_title\n",
    "    return clean_title.capitalize()\n",
    "\n",
    "# Step 7: Main Function\n",
    "def summarize_and_title(url):\n",
    "    \"\"\"Extracts text from a URL, summarizes it using LangChain, and generates a title.\"\"\"\n",
    "    try:\n",
    "        text = scrape_website(url)\n",
    "        summary = summarize_large_text(text)\n",
    "        title = generate_title(summary)\n",
    "\n",
    "        return title, summary\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\", \"\"\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://www.wix.com/encyclopedia/definition/artificial-intelligence\"\n",
    "    title, summary = summarize_and_title(url)\n",
    "    print(f\"Title: {title}\\nSummary: {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a4e8b0-8060-4cfc-976b-d468ceac2add",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
